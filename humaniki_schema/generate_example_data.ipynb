{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS\n",
    "1. for each table in humaniki\n",
    "2. generate an some example data\n",
    "3. store it in CSV in /example_data # or skip straight to part 5\n",
    "4. create a function to load the exmaple data into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, func, and_, or_\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "# from humaniki_schema.schema import fill, human, human_country, human_occupation, human_property, human_sitelink, label, \\\n",
    "#                                     metric, metric_aggregations, metric_coverage, metric_properties\n",
    "# import humaniki_schema.utils as hs_utils\n",
    "from schema import fill, human, human_country, human_occupation, human_property, human_sitelink, label, \\\n",
    "                                    metric, \\\n",
    "                                    metric_properties_j, metric_properties_n, \\\n",
    "                                    metric_aggregations_j, metric_aggregations_n, \\\n",
    "                                    metric_coverage, \\\n",
    "                                    project\n",
    "import utils as hs_utils\n",
    "\n",
    "try:\n",
    "    import pandas as pd\n",
    "except ImportError:\n",
    "    raise ImportError('For this script at least we need pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'example_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_engine = create_engine(\"mysql://{user}:{password}@{host}/{database}?charset=utf8\".format(\n",
    "    host = os.environ['HUMANIKI_MYSQL_HOST'],\n",
    "    user = os.environ['HUMANIKI_MYSQL_USER'],\n",
    "    password = os.environ['HUMANIKI_MYSQL_PASS'],\n",
    "    database = os.environ['HUMANIKI_MYSQL_DB']))\n",
    "\n",
    "# Base.metadata.bind = db_engine\n",
    "DBSession = sessionmaker(bind=db_engine)\n",
    "db_session = DBSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw data\n",
    "db_session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#order is important becuse of foreign key constraint\n",
    "all_tables = [human_country, human_occupation, human_property, human_sitelink, label, \n",
    "              metric_aggregations_j, \n",
    "              metric_properties_j,\n",
    "            metric_aggregations_n, \n",
    "              metric_properties_n,\n",
    "            metric_coverage,\n",
    "                metric,\n",
    "              human,\n",
    "              fill,\n",
    "             project]\n",
    "\n",
    "for table in all_tables:\n",
    "    db_session.query(table).delete()\n",
    "    db_session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fills(n=2):\n",
    "    fills = []\n",
    "    for i in range(n):\n",
    "        date = datetime.date(2018, 1, 1) + datetime.timedelta(weeks=i)\n",
    "        ftype = hs_utils.FillType.DUMP.value\n",
    "        detail = {'i':i, 'i_str': str(i)}\n",
    "        a_fill = fill(date=date, type=ftype, detail=detail)\n",
    "        fills.append(a_fill)\n",
    "\n",
    "    db_session.rollback()\n",
    "    db_session.add_all(fills)\n",
    "    db_session.commit()\n",
    "    return fills\n",
    "\n",
    "fills = make_fills()\n",
    "curr_fill = fills[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def make_humans():\n",
    "    humans_f = os.path.join(data_dir, 'denelezh_humans_500.tsv')\n",
    "\n",
    "    humans_df = pd.read_csv(humans_f, sep='\\t').rename(columns={\"birthyear\":'year_of_birth'})\n",
    "\n",
    "    humans_df['year_of_death'] = humans_df['year_of_birth'].apply(lambda yob: yob+100 if yob is not None else None)\n",
    "\n",
    "    humans_df = humans_df.replace(dict(year_of_birth={pd.np.nan: None}, year_of_death={pd.np.nan: None}))\n",
    "\n",
    "    humans = []\n",
    "\n",
    "    for fill in fills:\n",
    "        fill_id = fill.id\n",
    "        for ind, row in humans_df.iterrows():\n",
    "            a_human = human(fill_id=fill_id, qid=row['id'], \n",
    "                            year_of_birth=row['year_of_birth'],\n",
    "                            year_of_death=row['year_of_death'],\n",
    "                           gender=row['gender'],\n",
    "                           sitelink_count=row['sitelinks'])\n",
    "            humans.append(a_human)\n",
    "\n",
    "    db_session.rollback()\n",
    "    db_session.add_all(humans)\n",
    "    db_session.commit()\n",
    "    return humans\n",
    "\n",
    "humans = make_humans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_from_file(fname, schema_table, table_tsv_map, include_fill_col=True):\n",
    "    table_f = os.path.join(data_dir, fname)\n",
    "    table_df = pd.read_csv(table_f, sep='\\t')\n",
    "    insert_rows = []\n",
    "\n",
    "    for fill in fills:\n",
    "        fill_id = fill.id\n",
    "        for ind, row in table_df.iterrows():\n",
    "            params = {'fill_id':fill_id}\n",
    "            for table_name, tsv_name in table_tsv_map.items():\n",
    "                    params[table_name] = row[tsv_name]\n",
    "            a_row = schema_table(**params)\n",
    "            insert_rows.append(a_row)\n",
    "\n",
    "    db_session.rollback()\n",
    "    db_session.add_all(insert_rows)\n",
    "    db_session.commit()\n",
    "    return insert_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = make_table_from_file(fname='denelezh_human_country.tsv',\n",
    "                                 schema_table=human_country,\n",
    "                                table_tsv_map={'human_id':'human','country':'country'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupations = make_table_from_file(fname='denelezh_human_occupation.tsv',\n",
    "                                    schema_table=human_occupation,\n",
    "                                table_tsv_map={'human_id':'human','occupation':'occupation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sitelinks = make_table_from_file(fname='denelezh_human_sitelink.tsv', \n",
    "                                schema_table=human_sitelink,\n",
    "                          table_tsv_map={'human_id':'human','sitelink':'sitelink'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = make_table_from_file(fname='denelezh_label.tsv', \n",
    "                                schema_table=label,\n",
    "                          table_tsv_map={'qid':'id','lang':'lang','label':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_csv_sql = '''\n",
    "# LOAD DATA INFILE 'example_data/denelezh_project.tsv' INTO TABLE project\n",
    "# FIELDS TERMINATED BY '\\t' ENCLOSED BY ''\n",
    "# LINES TERMINATED BY '\\r\\n'\n",
    "# IGNORE 1 LINES;\n",
    "# '''\n",
    "# db_engine.execute(project_csv_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_table_exactly_from_file(fname, schema_table, table_tsv_map):\n",
    "    table_f = os.path.join(data_dir, fname)\n",
    "    table_df = pd.read_csv(table_f, sep='\\t').replace(dict(type={pd.np.nan: None}))\n",
    "    insert_rows = []\n",
    "\n",
    "    for ind, row in table_df.iterrows():\n",
    "        params = {}\n",
    "        for table_name, tsv_name in table_tsv_map.items():\n",
    "                params[table_name] = row[tsv_name]\n",
    "        a_row = schema_table(**params)\n",
    "        insert_rows.append(a_row)\n",
    "\n",
    "    db_session.rollback()\n",
    "    db_session.add_all(insert_rows)\n",
    "    db_session.commit()\n",
    "    return insert_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "projects = make_table_exactly_from_file(fname='denelezh_project.tsv',\n",
    "                               schema_table=project,\n",
    "                               table_tsv_map={'type':'type','code':'code','label':'label','url':'url'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## metrics\n",
    "1. geographic metric\n",
    "1. by language\n",
    "2. multi - language / geography\n",
    "3. multi - lanaguge / geography / occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_agg_vals(agg_vals):\n",
    "#     agg_vals_rec = db_session.query(metric_aggregations).filter_by(aggregations=agg_vals).one_or_none()\n",
    "        # select id, aggregations from metric_aggregations\n",
    "        #     where json_length(aggregations)=2\n",
    "        #         and json_extract(aggregations, '$[1]')=10\n",
    "        #         and json_extract(aggregations, '$[0]')=6581097\n",
    "    quoted_agg_vals = [f\"'{val}'\" if isinstance(val, str) else val for val in agg_vals] \n",
    "    agg_equals_parts = [ f\"and json_extract(aggregations, '$[{pos}]')={val}\" for pos, val in enumerate(quoted_agg_vals)]\n",
    "    \n",
    "    agg_equals_sql = f'''select id, aggregations from metric_aggregations_j where\n",
    "                        json_length(aggregations)={len(agg_vals)}\n",
    "                        {' '.join(agg_equals_parts)}\n",
    "                        ;\n",
    "                        '''\n",
    "#     print(agg_equals_sql)\n",
    "    agg_vals_rec = db_engine.execute(agg_equals_sql).fetchall()\n",
    "#     print(agg_vals_rec)\n",
    "    if not agg_vals_rec:\n",
    "#         print(agg_vals , 'not found')\n",
    "        a_metric_aggregation = metric_aggregations_j(aggregations=agg_vals)\n",
    "        db_session.rollback()\n",
    "        db_session.add(a_metric_aggregation)\n",
    "        db_session.commit()\n",
    "        return a_metric_aggregation.aggregations\n",
    "    else:\n",
    "        assert len(agg_vals_rec)==1\n",
    "        return agg_vals_rec[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6581097, 'fff']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_or_create_agg_vals([6581097, 'fff'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_metric_props(metric_props):\n",
    "#     metric_props_rec = db_session.query(metric_properties).filter_by(properties=metric_props).one_or_none()\n",
    "    metric_equals_parts = [ f\"and json_extract(properties, '$[{pos}]')={val}\" for pos, val in enumerate(metric_props)]\n",
    "    \n",
    "    metric_equals_sql = f'''select id, properties from metric_properties_j where\n",
    "                        json_length(properties)={len(metric_props)}\n",
    "                        {' '.join(metric_equals_parts)}\n",
    "                        ;\n",
    "                        '''\n",
    "#     print(metric_equals_sql)\n",
    "    metric_props_rec = db_engine.execute(metric_equals_sql).fetchall()\n",
    "    if not metric_props_rec:\n",
    "#         print(metric_props)\n",
    "        a_metric_properties = metric_properties_j(properties=metric_props)\n",
    "        db_session.rollback()\n",
    "        db_session.add(a_metric_properties)\n",
    "        db_session.commit()\n",
    "        return a_metric_properties.properties\n",
    "    else:\n",
    "        assert len(metric_props_rec)==1\n",
    "        return metric_props_rec[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6581097, 13]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_or_create_agg_vals([6581097, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_props = get_or_create_metric_props([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT human.gender AS human_gender, human_country.country AS human_country_country, count(human.gender) AS count_1 \n",
      "FROM human INNER JOIN human_country ON human.qid = human_country.human_id AND human.fill_id = human_country.fill_id \n",
      "WHERE human.fill_id = %s GROUP BY human_country.country, human.gender\n"
     ]
    }
   ],
   "source": [
    "def generate_geo_metrics():\n",
    "    geo_metric_q = db_session.query(human.gender, human_country.country, func.count(human.gender)) \\\n",
    "    .join(human_country, and_(human.qid==human_country.human_id, human.fill_id==human_country.fill_id))\\\n",
    "    .filter(human.fill_id==curr_fill)\\\n",
    "    .group_by(human_country.country, human.gender)\n",
    "\n",
    "    geo_metric_res = geo_metric_q.all()\n",
    "\n",
    "    print(str(geo_metric_q))\n",
    "\n",
    "#     geo_metric_q = db_session.query(human.gender, human_country.country, func.count(human.gender)) \\\n",
    "#     .join(human_country).filter(human.fill_id==curr_fill)\\\n",
    "#     .group_by(human_country.country, human.gender)\n",
    "\n",
    "#     geo_metric_res = geo_metric_q.all()\n",
    "    return geo_metric_res\n",
    "geo_metric_res = generate_geo_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_geo_metrics():\n",
    "    geo_metrics = []\n",
    "    for gender, country, count in geo_metric_res:\n",
    "        agg_vals_id = get_or_create_agg_vals([gender, country])\n",
    "        m_props_id = get_or_create_metric_props([-1])\n",
    "    #     db_session.commit()\n",
    "        fills_id = curr_fill\n",
    "        db_session.rollback()\n",
    "        a_metric = metric(fill_id=fills_id,\n",
    "#                          facet='geography',\n",
    "                         population_id=hs_utils.PopulationDefinition.ALL_WIKIDATA.value,\n",
    "                         properties_id=m_props_id,\n",
    "                         aggregations_id=agg_vals_id,\n",
    "                         bias_value=gender,\n",
    "                         total=count)\n",
    "#         print(a_metric)\n",
    "        geo_metrics.append(a_metric)\n",
    "#     db_session.add_all(geo_metrics)\n",
    "#     db_session.commit()\n",
    "    return geo_metrics\n",
    "geo_metrics = insert_geo_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_session.add_all(geo_metrics)\n",
    "db_session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_metrics[0].population_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(human.gender), str(func.count(human.gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_single_facet_metric(agg_table, agg_table_col):\n",
    "    query_columns = human.gender, agg_table_col, func.count(human.gender)\n",
    "    query_columns_str = [str(c) for c in query_columns]\n",
    "    metric_q = db_session.query(*query_columns) \\\n",
    "    .join(agg_table, and_(human.qid==agg_table.human_id, human.fill_id==agg_table.fill_id))\\\n",
    "    .filter(human.fill_id==curr_fill)\\\n",
    "    .group_by(agg_table_col, human.gender)\n",
    "\n",
    "    metric_res = metric_q.all()\n",
    "\n",
    "#     print(str(metric_q))\n",
    "    return query_columns_str, metric_res\n",
    "\n",
    "proj_metric_strs, proj_metric_res = generate_single_facet_metric(human_sitelink, human_sitelink.sitelink)\n",
    "\n",
    "\n",
    "metric_q = db_session.query(human.gender, human_sitelink.sitelink, func.count(human.gender)) \\\n",
    ".join(human_sitelink, and_(human.qid==human_sitelink.human_id, human.fill_id==human_sitelink.fill_id))\\\n",
    ".join(project, human_sitelink.sitelink==project.code)\\\n",
    ".filter(human.fill_id==curr_fill)\\\n",
    ".filter(project.type=='wikipedia')\\\n",
    ".group_by(human_sitelink.sitelink, human.gender)\n",
    "\n",
    "proj_metric_res = metric_q.all()\n",
    "\n",
    "def get_props_id_from_str(prop):\n",
    "    return {'sitelink':-2}[prop]\n",
    "\n",
    "def get_facet_id_from_str(prop):\n",
    "    return {'sitelink':-2}[prop]\n",
    "\n",
    "def insert_single_prop_metrics(facet, prop, metric_col_strs, metric_rows):\n",
    "    sf_metrics = []\n",
    "    for gender, prop_val, count in metric_rows:\n",
    "        agg_vals_id = get_or_create_agg_vals([gender, prop_val])\n",
    "        props_pid = get_props_id_from_str(prop)\n",
    "        m_props_id = get_or_create_metric_props([props_pid])\n",
    "        fills_id = curr_fill\n",
    "#         db_session.rollback()\n",
    "        a_metric = metric(fill_id=fills_id,\n",
    "                         population_id=hs_utils.PopulationDefinition.GTE_ONE_SITELINK.value,\n",
    "                         properties_id=m_props_id,\n",
    "                         aggregations_id=agg_vals_id,\n",
    "                         bias_value=gender,\n",
    "                         total=count)\n",
    "        sf_metrics.append(a_metric)\n",
    "\n",
    "    return sf_metrics\n",
    "\n",
    "metrics = insert_single_prop_metrics(facet='project', prop='sitelink', \n",
    "                                     metric_col_strs=proj_metric_strs, \n",
    "                                     metric_rows=proj_metric_res)\n",
    "\n",
    "db_session.add_all(metrics)\n",
    "db_session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_session.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_metric_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
